{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twiitter API: extract tweets of Trump and Trudeau to compare their activity on Twitter (NLTK/Regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data extraction with API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Firstly, Twitter does not allow to extract more than 200 tweets per one time. This issue can be\n",
    "solved by adding **“max_id”** option. Each iteration will extract different tweets because max_id is changing in the end of each iteration<br>\n",
    "- Secondly, by default twitter extracts a truncated version of a tweet. To force twitter to\n",
    "output the full version of tweet, an option of the call should be set to\n",
    "**“tweet_mode=extended”**;<br>\n",
    "To compare different attributes of Trumps’ and Trudeaus’ tweets, python language, some\n",
    "libraries(pandas, numpy) and regular expressions were used.\n",
    "- Thirdly, **\"include_rts\"** is set to \"False\" to prevent retweets from being saved. Only tweets of autors are analysed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import FreqDist\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract data with the help of API(Trudeau)** <br>\n",
    "First loop is needed to initialize max_id, second loop updates it constantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAADmO4QAAAAAA1l35b3JfTyYe8rDAX0q7nhR%2BBis%3D90KK4CMhxUBYfLFslUyJmusiEVnhBRLVmIG4Nnb2b6R2SlVxmU',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('screen_name', 'JustinTrudeau'),\n",
    "    ('include_rts', 'false'),\n",
    "    ('count', '200'),\n",
    "    ('tweet_mode', 'extended'),\n",
    ")\n",
    "\n",
    "response = requests.get('https://api.twitter.com:443/1.1/statuses/user_timeline.json', headers=headers, params=params)\n",
    "response_json=response.json()\n",
    "max_id = response_json[-1]['id']\n",
    "\n",
    "import requests\n",
    "#1500 - number of tweets\n",
    "while len(response_json)<1500:\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAADmO4QAAAAAA1l35b3JfTyYe8rDAX0q7nhR%2BBis%3D90KK4CMhxUBYfLFslUyJmusiEVnhBRLVmIG4Nnb2b6R2SlVxmU',\n",
    "    }\n",
    "    \n",
    "    params = (\n",
    "        ('screen_name', 'JustinTrudeau'),\n",
    "        ('include_rts', 'false'),\n",
    "        ('count', '200'),\n",
    "        ('tweet_mode', 'extended'),\n",
    "        ('max_id', max_id),\n",
    "    )\n",
    "    \n",
    "    response = requests.get('https://api.twitter.com:443/1.1/statuses/user_timeline.json', headers=headers, params=params)\n",
    "    response_json_new=response.json()\n",
    "    response_json  += response_json_new\n",
    "    max_id = response_json[-1]['id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataframe of the date of a tweet and its' content (text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_at_list_trud = []\n",
    "for time in range(len(response_json)):\n",
    "    created_at_list_trud.append(response_json[time][\"created_at\"])\n",
    "\n",
    "texts_trud = []\n",
    "for el in range(len(response_json)):\n",
    "    texts_trud.append(response_json[el][\"full_text\"])\n",
    "\n",
    "df_trud = pd.DataFrame(\n",
    "    {'Text': texts_trud,\n",
    "     'created_at': created_at_list_trud\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required to see more text of tweet in Jupyter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 140\n",
    "pd.options.display.max_colwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Innovators, researchers, and entrepreneurs move Canada forward - creating good jobs and growing our economy. Here’s how we’re making sur...</td>\n",
       "      <td>Fri Jul 27 16:10:24 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les innovateurs, les chercheurs et les entrepreneurs font avancer le Canada : ils créent de bons emplois et font croître notre économie....</td>\n",
       "      <td>Fri Jul 27 16:09:50 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Today, we honour the brave Canadians who fought for freedom and democracy during the Korean War: https://t.co/4cVOhJ4PFz</td>\n",
       "      <td>Fri Jul 27 12:07:57 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aujourd’hui, nous rendons hommage aux braves Canadiens qui se sont battus au nom de la liberté et de la démocratie pendant la guerre de ...</td>\n",
       "      <td>Fri Jul 27 12:07:45 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hardworking Canadians shouldn’t have to worry about having enough money to retire. That’s why we’ve improved and strengthened the Canada...</td>\n",
       "      <td>Thu Jul 26 23:01:13 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          Text  \\\n",
       "0  Innovators, researchers, and entrepreneurs move Canada forward - creating good jobs and growing our economy. Here’s how we’re making sur...   \n",
       "1  Les innovateurs, les chercheurs et les entrepreneurs font avancer le Canada : ils créent de bons emplois et font croître notre économie....   \n",
       "2                     Today, we honour the brave Canadians who fought for freedom and democracy during the Korean War: https://t.co/4cVOhJ4PFz   \n",
       "3  Aujourd’hui, nous rendons hommage aux braves Canadiens qui se sont battus au nom de la liberté et de la démocratie pendant la guerre de ...   \n",
       "4  Hardworking Canadians shouldn’t have to worry about having enough money to retire. That’s why we’ve improved and strengthened the Canada...   \n",
       "\n",
       "                       created_at  \n",
       "0  Fri Jul 27 16:10:24 +0000 2018  \n",
       "1  Fri Jul 27 16:09:50 +0000 2018  \n",
       "2  Fri Jul 27 12:07:57 +0000 2018  \n",
       "3  Fri Jul 27 12:07:45 +0000 2018  \n",
       "4  Thu Jul 26 23:01:13 +0000 2018  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract data with the help of API(Trump)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAADmO4QAAAAAA1l35b3JfTyYe8rDAX0q7nhR%2BBis%3D90KK4CMhxUBYfLFslUyJmusiEVnhBRLVmIG4Nnb2b6R2SlVxmU',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('screen_name', 'realDonaldTrump'),\n",
    "    ('include_rts', 'false'),\n",
    "    ('count', '200'),\n",
    "    ('tweet_mode', 'extended'),\n",
    ")\n",
    "\n",
    "response = requests.get('https://api.twitter.com:443/1.1/statuses/user_timeline.json', headers=headers, params=params)\n",
    "response_json_trump=response.json()\n",
    "#max id to insert into next loop\n",
    "max_id = response_json_trump[-1]['id']\n",
    "\n",
    "import requests\n",
    "#include_rts is set to False, but count includes retweets. so the easiest way to get some number of tweets - while loop\n",
    "while len(response_json_trump)<1500:\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAADmO4QAAAAAA1l35b3JfTyYe8rDAX0q7nhR%2BBis%3D90KK4CMhxUBYfLFslUyJmusiEVnhBRLVmIG4Nnb2b6R2SlVxmU',\n",
    "    }\n",
    "    \n",
    "    params = (\n",
    "        ('screen_name', 'realDonaldTrump'),\n",
    "        ('include_rts', 'false'),\n",
    "        ('count', '200'),\n",
    "        ('tweet_mode', 'extended'),\n",
    "        ('max_id', max_id),\n",
    "    )\n",
    "    \n",
    "    response = requests.get('https://api.twitter.com:443/1.1/statuses/user_timeline.json', headers=headers, params=params)\n",
    "    response_json_new=response.json()\n",
    "    response_json_trump  += response_json_new\n",
    "    max_id = response_json_trump[-1]['id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataframe of the date of a tweet and its' content (text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_at_list_trump = []\n",
    "for time in range(len(response_json_trump)):\n",
    "    created_at_list_trump.append(response_json_trump[time][\"created_at\"])\n",
    "\n",
    "texts_trump = []\n",
    "for el in range(len(response_json_trump)):\n",
    "    texts_trump.append(response_json_trump[el][\"full_text\"])\n",
    "    \n",
    "\n",
    "df_trump = pd.DataFrame(\n",
    "    {'Text': texts_trump,\n",
    "     'created_at': created_at_list_trump\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We must have Border Security, get rid of Chain, Lottery, Catch &amp;amp; Release Sanctuary Cities - go to Merit based Immigration. Protect I...</td>\n",
       "      <td>Mon Jul 30 11:57:34 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....Also, why is Mueller only appointing Angry Dems, some of whom have worked for Crooked Hillary, others, including himself, have worke...</td>\n",
       "      <td>Sun Jul 29 20:20:39 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is Robert Mueller ever going to release his conflicts of interest with respect to President Trump, including the fact that we had a very...</td>\n",
       "      <td>Sun Jul 29 20:12:15 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is No Collusion! The Robert Mueller Rigged Witch Hunt, headed now by 17 (increased from 13, including an Obama White House lawyer)...</td>\n",
       "      <td>Sun Jul 29 19:35:14 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...and the Amazon Washington Post do nothing but write bad stories even on very positive achievements - and they will never change!</td>\n",
       "      <td>Sun Jul 29 19:09:19 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          Text  \\\n",
       "0  We must have Border Security, get rid of Chain, Lottery, Catch &amp; Release Sanctuary Cities - go to Merit based Immigration. Protect I...   \n",
       "1  ....Also, why is Mueller only appointing Angry Dems, some of whom have worked for Crooked Hillary, others, including himself, have worke...   \n",
       "2  Is Robert Mueller ever going to release his conflicts of interest with respect to President Trump, including the fact that we had a very...   \n",
       "3  There is No Collusion! The Robert Mueller Rigged Witch Hunt, headed now by 17 (increased from 13, including an Obama White House lawyer)...   \n",
       "4          ...and the Amazon Washington Post do nothing but write bad stories even on very positive achievements - and they will never change!   \n",
       "\n",
       "                       created_at  \n",
       "0  Mon Jul 30 11:57:34 +0000 2018  \n",
       "1  Sun Jul 29 20:20:39 +0000 2018  \n",
       "2  Sun Jul 29 20:12:15 +0000 2018  \n",
       "3  Sun Jul 29 19:35:14 +0000 2018  \n",
       "4  Sun Jul 29 19:09:19 +0000 2018  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limit number of tweets to 1500**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trud = df_trud[:1500]\n",
    "df_trump = df_trump[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to answer\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the average number of times they tweet per day?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answers this question, datasets should be grouped on a daily basis to count number of\n",
    "tweets per day. It was done by extracting part of a date, converting this part to datetime\n",
    "and counting number of tweets per day on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract date from text\n",
    "for i, row in df_trump.iterrows():\n",
    "    value = df_trump['created_at'][i][4:10] +\", \"+ df_trump['created_at'][i][-4:]\n",
    "    df_trump.set_value(i,'date', value)\n",
    "    \n",
    "#convert to datetime\n",
    "df_trump['date_conv'] = pd.to_datetime(df_trump['date'])\n",
    "\n",
    "#group on a daily basis, count tweets\n",
    "df_trump_1 = df_trump.resample('D', on='date_conv').count()\n",
    "\n",
    "#Trudeau\n",
    "#extract date from text\n",
    "for i, row in df_trud.iterrows():\n",
    "    value = df_trud['created_at'][i][4:10] +\", \"+ df_trud['created_at'][i][-4:]\n",
    "    df_trud.set_value(i,'date', value)\n",
    "    \n",
    "#convert to datetime\n",
    "df_trud['date_conv'] = pd.to_datetime(df_trud['date'])\n",
    "\n",
    "#group on a daily basis, count tweets\n",
    "df_trud_1 = df_trud.resample('D', on='date_conv').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tweets per day of Trump:  7.21\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of tweets per day of Trump: \", \"%.2f\" % df_trump_1[\"Text\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tweets per day of Trudeau:  6.82\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of tweets per day of Trudeau: \", \"%.2f\" % df_trud_1[\"Text\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, on average, Trump posts more tweets by 1 per day. (Even though Trudeau posts same tweets in English and in French)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What day of the week do they tweet most frequently?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question the same method will be used, the only difference that now the day of the\n",
    "week will be extracted and grouped by the variable that represents this day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract day of week from text\n",
    "for i, row in df_trump.iterrows():\n",
    "    df_trump.set_value(i,'dayofweek', df_trump['created_at'][i][:3])\n",
    "    \n",
    "#group by day of a week to find the most popular day to tweet\n",
    "df_trump_2 = df_trump.groupby('dayofweek').count()\n",
    "\n",
    "#Trud\n",
    "#extract day of week from text\n",
    "for i, row in df_trud.iterrows():\n",
    "    df_trud.set_value(i,'dayofweek', df_trud['created_at'][i][:3])\n",
    "    \n",
    "#group by day of a week to find the most popular day to tweet\n",
    "df_trud_2 = df_trud.groupby('dayofweek').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trudeau**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayofweek\n",
       "Wed    292\n",
       "Thu    279\n",
       "Fri    248\n",
       "Tue    244\n",
       "Mon    162\n",
       "Sun    138\n",
       "Sat    137\n",
       "Name: Text, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trud_2.sort_values(by=['date_conv'], ascending=False)['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayofweek\n",
       "Wed    269\n",
       "Thu    247\n",
       "Tue    220\n",
       "Fri    218\n",
       "Sat    197\n",
       "Mon    192\n",
       "Sun    157\n",
       "Name: Text, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trump_2.sort_values(by=['date_conv'], ascending=False)['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both Trump and Trudeau, Wednesday and Thursday are the most popular days to tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ratio of the word \"fake\" vs \"real\"?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex was used to find out how many times a word “fake” and a word “real” appeared in tweets.\n",
    "The regex “findall” code was looped across every tweet to count instances of these words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump: Counts of 'real' 67 \n",
      "Counts of 'fake' 1 \n",
      "Proportion of fake to real 0.014925373134328358\n"
     ]
    }
   ],
   "source": [
    "count_real = 0\n",
    "count_fake = 0\n",
    "\n",
    "#count number of occurences for both words\n",
    "for element in range(0, df_trump['Text'].count()):\n",
    "    text = df_trump['Text'][element]\n",
    "    extr_real = re.findall(r'(real)', text)\n",
    "    extr_fake = re.findall(r'(fake)', text)\n",
    "    for el in extr_real:\n",
    "        count_real +=1\n",
    "    for el in extr_fake:\n",
    "        count_fake +=1\n",
    "        \n",
    "print(\"Trump: Counts of 'real'\", count_real,\n",
    "      \"\\nCounts of 'fake'\", count_fake,\n",
    "      \"\\nProportion of fake to real\", \n",
    "      count_fake/count_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trudeau**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trudeau: Counts of 'real' 20 \n",
      "Counts of 'fake' 0 \n",
      "Proportion of fake to real 0.0\n"
     ]
    }
   ],
   "source": [
    "count_real = 0\n",
    "count_fake = 0\n",
    "\n",
    "#count number of occurences for both words\n",
    "for element in range(0, df_trud['Text'].count()):\n",
    "    text = df_trud['Text'][element]\n",
    "    extr_real = re.findall(r'(real)', text)\n",
    "    extr_fake = re.findall(r'(fake)', text)\n",
    "    for el in extr_real:\n",
    "        count_real +=1\n",
    "    for el in extr_fake:\n",
    "        count_fake +=1\n",
    "        \n",
    "print(\"Trudeau: Counts of 'real'\", count_real,\n",
    "      \"\\nCounts of 'fake'\", count_fake,\n",
    "      \"\\nProportion of fake to real\", \n",
    "      count_fake/count_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the proportion of using these words for Trump in 1 to 68, while Trudeau did not use a\n",
    "word ‘fake’ in last 1500 tweets at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ratio of the word \"good\" vs \"bad\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump: Counts of 'good' 94 \n",
      "Counts of 'bad' 63 \n",
      "Proportion of bad to good 0.6702127659574468\n"
     ]
    }
   ],
   "source": [
    "count_good = 0\n",
    "count_bad = 0\n",
    "\n",
    "for element in range(0, df_trump['Text']\n",
    "                     .count()):\n",
    "    text = df_trump['Text'][element]\n",
    "    extr_good = re.findall(r'(good)', text)\n",
    "    extr_bad = re.findall(r'(bad)', text)\n",
    "    for el in extr_good:\n",
    "        count_good +=1\n",
    "    for el in extr_bad:\n",
    "        count_bad +=1\n",
    "\n",
    "print(\"Trump: Counts of 'good'\", count_good,\n",
    "      \"\\nCounts of 'bad'\", count_bad,\n",
    "      \"\\nProportion of bad to good\", \n",
    "      count_bad/count_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trudeau: Counts of 'good' 46 \n",
      "Counts of 'bad' 7 \n",
      "Proportion of bad to good 0.15217391304347827\n"
     ]
    }
   ],
   "source": [
    "count_good = 0\n",
    "count_bad = 0\n",
    "\n",
    "for element in range(0, df_trud['Text']\n",
    "                     .count()):\n",
    "    text = df_trud['Text'][element]\n",
    "    extr_good = re.findall(r'(good)', text)\n",
    "    extr_bad = re.findall(r'(bad)', text)\n",
    "    for el in extr_good:\n",
    "        count_good +=1\n",
    "    for el in extr_bad:\n",
    "        count_bad +=1\n",
    "\n",
    "print(\"Trudeau: Counts of 'good'\", count_good,\n",
    "      \"\\nCounts of 'bad'\", count_bad,\n",
    "      \"\\nProportion of bad to good\", \n",
    "      count_bad/count_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trump uses a word “good” by 67% more often than a word “bad”, while Trudeau uses \"good\" 15% more often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many times a week does Trump use his surname?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A new column was created that indicates the week number of a tweet\n",
    "2. A regex was used to create another column with a Boolean variables that show if a surname\n",
    "was used in this tweet or not\n",
    "3. And finally, data was grouped by a week number to count number of times a surname was\n",
    "used per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of times per week when Trump uses his surname in Twitter:  4.172413793103448\n"
     ]
    }
   ],
   "source": [
    "#extract a week number\n",
    "for i, row in df_trump.iterrows():\n",
    "    df_trump.set_value(i,'weekn', df_trump['date_conv'][i].week)\n",
    "\n",
    "#create a boolean variable that shows surname usage\n",
    "for i, row in df_trump.iterrows():\n",
    "    text = df_trump['Text'][i]\n",
    "    lst = re.findall(r'(Trump)', text)\n",
    "    if len(lst)>0:\n",
    "        df_trump.set_value(i,'last_name', \"True\")\n",
    "    else:\n",
    "        df_trump.set_value(i,'last_name', \"False\")\n",
    "        \n",
    "#mean tweets with last name per weeek\n",
    "df_trump_4 = df_trump.groupby(['weekn', 'last_name']).count()\n",
    "df_trump_4 = df_trump_4.reset_index()\n",
    "df_trump_4 = df_trump_4.loc[df_trump_4['last_name'] == 'True']\n",
    "print(\"Average number of times per week when Trump uses his surname in Twitter: \",df_trump_4[\"created_at\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Peak times they tweet?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time an hour of the tweet was extracted and used for grouping to count number of tweets per\n",
    "hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>date_conv</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekn</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Text  created_at  date  date_conv  dayofweek  weekn  last_name\n",
       "timev                                                                \n",
       "13      177         177   177        177        177    177        177\n",
       "11      166         166   166        166        166    166        166\n",
       "12      159         159   159        159        159    159        159\n",
       "20      104         104   104        104        104    104        104\n",
       "14       99          99    99         99         99     99         99\n",
       "10       88          88    88         88         88     88         88\n",
       "22       75          75    75         75         75     75         75\n",
       "19       67          67    67         67         67     67         67\n",
       "17       65          65    65         65         65     65         65\n",
       "00       60          60    60         60         60     60         60"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract time\n",
    "for i, row in df_trump.iterrows():\n",
    "    value = df_trump['created_at'][i][11:13]\n",
    "    df_trump.set_value(i,'timev', value)\n",
    "\n",
    "#the most popular time of day\n",
    "df_trump_6=df_trump.groupby('timev').count()\n",
    "df_trump_6.sort_values(by=['created_at'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trudeau**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>date_conv</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Text  created_at  date  date_conv  dayofweek\n",
       "timev                                              \n",
       "22      145         145   145        145        145\n",
       "18      132         132   132        132        132\n",
       "14      118         118   118        118        118\n",
       "21      112         112   112        112        112\n",
       "20      111         111   111        111        111\n",
       "15      104         104   104        104        104\n",
       "19      101         101   101        101        101\n",
       "00      100         100   100        100        100\n",
       "17       95          95    95         95         95\n",
       "23       89          89    89         89         89"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract time\n",
    "for i, row in df_trud.iterrows():\n",
    "    value = df_trud['created_at'][i][11:13]\n",
    "    df_trud.set_value(i,'timev', value)\n",
    "\n",
    "#the most popular time of day\n",
    "df_trud_6=df_trud.groupby('timev').count()\n",
    "df_trud_6.sort_values(by=['created_at'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trump prefers to tweet from 10AM till 2PM, in the afternoon, while Trudeau prefers to leave tweets\n",
    "from 8PM to 10PM, in the evening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of times they use their countries name in their tweets?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Boolean variable was created to indicate if\n",
    "country name was used or not. After that the total number of usages and non-usages were found by\n",
    "grouping:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10 % of times name of contry is used\n"
     ]
    }
   ],
   "source": [
    "#create a boolean variable that shows country name usage\n",
    "for i, row in df_trump.iterrows():\n",
    "    text = df_trump['Text'][i]\n",
    "    lst = re.findall(r'(US|USA|United States)', text)\n",
    "    if len(lst)>0:\n",
    "        df_trump.set_value(i,'country', \"True\")\n",
    "    else:\n",
    "        df_trump.set_value(i,'country', \"False\")\n",
    "        \n",
    "#counting\n",
    "df_trump_4 = df_trump.groupby(['country']).count()\n",
    "#df_trump_4 = df_trump_4.reset_index()\n",
    "print(\"%.2f\" % (df_trump_4['Text']['True']/df_trump_4['Text']['False']), \"% of times name of contry is used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trudeau**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43 % of times name of contry is used\n"
     ]
    }
   ],
   "source": [
    "#create a boolean variable that shows country name usage\n",
    "for i, row in df_trud.iterrows():\n",
    "    text = df_trud['Text'][i]\n",
    "    lst = re.findall(r'(Canada)', text)\n",
    "    if len(lst)>0:\n",
    "        df_trud.set_value(i,'country', \"True\")\n",
    "    else:\n",
    "        df_trud.set_value(i,'country', \"False\")\n",
    "        \n",
    "#counting\n",
    "df_trud_4 = df_trud.groupby(['country']).count()\n",
    "#df_trud_4 = df_trud.reset_index()\n",
    "\n",
    "print(\"%.2f\" % (df_trud_4['Text']['True']/df_trud_4['Text']['False']), \"% of times name of contry is used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trudeau tends to use the name of Canada much more often than Trump uses the name of US. More\n",
    "than 40% of tweets of Trudeau contain name of his country, while only every 10th tweet of Trump has a\n",
    "name of US in some form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the average number of words per tweet?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate average number of words in a tweet, first of all, a total number of words of every tweet\n",
    "was put in list and then the mean of numbers of this list was found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trudeau**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trudeau.\n",
      "Average number of words:  33.82\n"
     ]
    }
   ],
   "source": [
    "#average number of words in a tweet\n",
    "lst=[]\n",
    "\n",
    "for i, row in df_trump.iterrows():\n",
    "    lst.append(len(df_trump['Text'][i].split(' ')))\n",
    "    \n",
    "import numpy as np\n",
    "print(\"Trudeau.\\nAverage number of words: \",\"%.2f\" % np.mean(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump.\n",
      "Average number of words:  31.06\n"
     ]
    }
   ],
   "source": [
    "#average number of words in a tweet\n",
    "lst=[]\n",
    "\n",
    "for i, row in df_trump.iterrows():\n",
    "    lst.append(len(df_trud['Text'][i].split(' ')))\n",
    "    \n",
    "import numpy as np\n",
    "print(\"Trump.\\nAverage number of words: \",\"%.2f\" % np.mean(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trump tends to use on average 3 words less than Trudeau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the most popular words used by Trump and Trudeau?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('that', 434),\n",
       " ('with', 425),\n",
       " ('will', 382),\n",
       " ('great', 380),\n",
       " ('http', 365),\n",
       " ('have', 341),\n",
       " ('they', 267),\n",
       " ('&amp', 210),\n",
       " ('thi', 191),\n",
       " ('peopl', 189),\n",
       " ('countri', 181),\n",
       " ('veri', 172),\n",
       " ('democrat', 162),\n",
       " ('from', 148),\n",
       " ('their', 144),\n",
       " ('more', 143),\n",
       " ('want', 142),\n",
       " ('mani', 140),\n",
       " ('news', 130),\n",
       " ('just', 127),\n",
       " ('border', 123),\n",
       " ('been', 123),\n",
       " ('trade', 120),\n",
       " ('state', 119),\n",
       " ('about', 116),\n",
       " ('presid', 115),\n",
       " ('there', 114),\n",
       " ('fake', 113),\n",
       " ('make', 112),\n",
       " ('work', 107),\n",
       " ('must', 106),\n",
       " ('would', 105),\n",
       " ('time', 104),\n",
       " ('than', 102),\n",
       " ('year', 102),\n",
       " ('american', 100),\n",
       " ('good', 100),\n",
       " ('much', 99),\n",
       " ('thank', 97),\n",
       " ('trump', 91),\n",
       " ('back', 91),\n",
       " ('come', 88),\n",
       " ('what', 86),\n",
       " ('need', 84),\n",
       " ('should', 84),\n",
       " ('into', 83),\n",
       " ('america', 83),\n",
       " ('meet', 81),\n",
       " ('be', 81),\n",
       " ('never', 79)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#the words that appear he most in positive reviews\n",
    "import nltk\n",
    "porter = nltk.PorterStemmer()\n",
    "list_pos=[]\n",
    "for i in range(len(df_trump)):\n",
    "    list_pos.append(df_trump[\"Text\"].iloc[i])\n",
    "lst_words_pos = []\n",
    "for line in list_pos:\n",
    "    text_pos = re.split('\\n| |\\?|\\!|\\:|\\\"|\\(|\\)|\\...|\\;',line)\n",
    "    for word in text_pos:\n",
    "        if (len(word)>3 and not word.startswith('@') and not word.startswith('#') and word != 'RT'):\n",
    "            lst_words_pos.append(porter.stem(word.lower()))\n",
    "\n",
    "\n",
    "dist_pos = FreqDist(lst_words_pos) \n",
    "sorted_dist_pos = sorted(dist_pos.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_dist_pos[:50]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most frequent words of Trump: _people, country, democracy, fake, border, news, america_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http', 821),\n",
       " ('ttp', 594),\n",
       " ('pour', 502),\n",
       " ('nou', 382),\n",
       " ('canada', 341),\n",
       " ('&amp', 328),\n",
       " ('with', 221),\n",
       " ('work', 177),\n",
       " ('dan', 166),\n",
       " ('plu', 164),\n",
       " ('avec', 159),\n",
       " ('thi', 150),\n",
       " ('notr', 123),\n",
       " ('more', 121),\n",
       " ('vou', 120),\n",
       " ('canadian', 119),\n",
       " ('today', 111),\n",
       " ('leur', 108),\n",
       " ('canadien', 101),\n",
       " ('peopl', 101),\n",
       " ('tou', 101),\n",
       " ('travail', 96),\n",
       " ('thank', 93),\n",
       " ('will', 86),\n",
       " ('their', 85),\n",
       " ('we’r', 84),\n",
       " ('make', 81),\n",
       " ('tout', 81),\n",
       " ('about', 80),\n",
       " ('creat', 79),\n",
       " ('job', 79),\n",
       " ('cett', 79),\n",
       " ('great', 77),\n",
       " ('avon', 76),\n",
       " ('have', 74),\n",
       " ('from', 74),\n",
       " ('meet', 74),\n",
       " ('help', 72),\n",
       " ('congratul', 71),\n",
       " ('pay', 71),\n",
       " ('erci', 67),\n",
       " ('your', 67),\n",
       " ('togeth', 66),\n",
       " ('that', 64),\n",
       " ('félicit', 63),\n",
       " ('votr', 63),\n",
       " ('countri', 62),\n",
       " ('discuss', 62),\n",
       " ('protect', 59),\n",
       " ('aujourd’hui', 58)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#the words that appear he most in positive reviews\n",
    "import nltk\n",
    "porter = nltk.PorterStemmer()\n",
    "list_pos=[]\n",
    "for i in range(len(df_trud)):\n",
    "    list_pos.append(df_trud[\"Text\"].iloc[i])\n",
    "lst_words_pos = []\n",
    "for line in list_pos:\n",
    "    text_pos = re.split('\\n| |\\?|\\!|\\:|\\\"|\\(|\\)|\\...|\\;',line)\n",
    "    for word in text_pos:\n",
    "        if (len(word)>3 and not word.startswith('@') and not word.startswith('#') and word != 'RT'):\n",
    "            lst_words_pos.append(porter.stem(word.lower()))\n",
    "\n",
    "\n",
    "dist_pos = FreqDist(lst_words_pos) \n",
    "sorted_dist_pos = sorted(dist_pos.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_dist_pos[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most frequent words of Trudeau: _Canada, people, today, thank, congats, protect_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
